{
    "group": "AI",
    "content": "Google stellt Gemini 1.5 Pro vor",
    "short_title": "Gemini 1.5 Pro",
    "start": "2024-02-15",
    "details": "### Google revolutioniert die Datenverarbeitung mit Gemini 1.5 Pro\n\nAm 15. Februar 2024 kündigte Google Gemini 1.5 Pro an, ein mittelgroßes multimodales Modell, das einen Durchbruch in der Verarbeitung von Langkontext-Informationen darstellte. Obwohl es als mittelgroßes Modell eingestuft wurde, erreichte es eine Leistungsfähigkeit, die mit Googles größtem Vorgängermodell, Gemini 1.0 Ultra, vergleichbar war, benötigte aber deutlich weniger Rechenleistung.\n\n#### Technologische Fortschritte und die Rolle der KI\n\nDer entscheidende KI-Durchbruch von Gemini 1.5 Pro war die Einführung eines massiven Kontextfensters von standardmäßig 128.000 Token, das für eine begrenzte Gruppe von Entwicklern sogar auf bis zu 1 Million Token erweitert wurde. Dies war zum Zeitpunkt der Ankündigung das größte Kontextfenster aller verfügbaren Large-Scale-Modelle. Technologisch wurde dies durch eine neue \"Mixture-of-Experts\" (MoE)-Architektur ermöglicht, bei der das neuronale Netzwerk in kleinere \"Experten\"-Netzwerke aufgeteilt wird, die nur bei Bedarf aktiviert werden. Dies macht das Modell wesentlich effizienter im Training und in der Anwendung.\n\n#### Bedeutung und potenzieller Einfluss\n\nDie Fähigkeit, bis zu 1 Million Token zu verarbeiten, eröffnete völlig neue Anwendungsfälle. Entwickler konnten nun riesige Mengen an Informationen auf einmal verarbeiten, darunter ganze Codebasen mit zehntausenden Zeilen, stundenlange Videos oder umfangreiche Dokumentensammlungen. Dies ermöglichte eine tiefere und kontextbezogenere Analyse und Problemlösung, als es mit früheren Modellen möglich war. Gemini 1.5 Pro hat damit einen neuen Standard für die Fähigkeit von KI-Modellen gesetzt, große und komplexe Datenmengen zu verstehen und zu verarbeiten."
}