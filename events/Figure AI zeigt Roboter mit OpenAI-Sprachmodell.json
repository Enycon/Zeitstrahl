{
    "group": "Robotics",
    "content": "Figure AI zeigt Roboter mit OpenAI-Sprachmodell",
    "short_title": "Figure 01 OpenAI",
    "start": "2024-03-13",
    "details": "### Ein Roboter, der sehen, sprechen und handeln kann\n\nIm März 2024 veröffentlichte das Startup Figure AI ein Video, das als \"ChatGPT-Moment\" für die Robotik gilt. In der Demonstration führte der humanoide Roboter Figure 01 eine flüssige Konversation mit einem Menschen. Er konnte Objekte auf einem Tisch identifizieren, basierend auf dem Gespräch eine logische Handlung ableiten (z.B. dem Menschen einen Apfel geben) und diese Handlung präzise ausführen. Der Roboter erklärte dabei sogar seine Beweggründe in Echtzeit.\n\n#### Die Rolle der KI im Durchbruch\n\nDieser Durchbruch war eine direkte Symbiose aus Robotik und fortschrittlicher KI. Die Kameras des Roboters dienten als Augen, deren Bilder direkt an ein großes multimodales Sprachmodell von OpenAI gesendet wurden. Die KI verarbeitete die visuellen Daten und den Sprachbefehl, um eine passende Antwort und die notwendigen motorischen Befehle für die Roboterarme zu generieren. Die KI fungierte somit als das zentrale Gehirn des Roboters.\n\n#### Bedeutung und potenzieller Einfluss\n\nDiese Demonstration zeigte erstmals eindrucksvoll, wie die jüngsten Fortschritte bei Sprachmodellen Robotern ein echtes Verständnis ihrer Umgebung verleihen können. Statt starrer vorprogrammierter Routinen ermöglicht dies die Schaffung von Allzweckrobotern, die flexibel auf unvorhergesehene Situationen reagieren können. Dies hat das Potenzial, den Einsatz von humanoiden Robotern in Logistik, Einzelhandel und Pflege zu revolutionieren."
}