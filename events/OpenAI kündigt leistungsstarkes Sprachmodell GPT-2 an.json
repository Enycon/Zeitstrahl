{
    "group": "AI",
    "content": "OpenAI kündigt leistungsstarkes Sprachmodell GPT-2 an",
    "short_title": "GPT-2",
    "start": "2019-02-14",
    "details": "### GPT-2: Die KI, die \"zu gefährlich\" war, um sie zu veröffentlichen\n\nIm Februar 2019 stellte OpenAI GPT-2 vor, ein Modell, das mit 1,5 Milliarden Parametern deutlich größer und leistungsfähiger war als sein Vorgänger. Die Qualität des generierten Textes war so hoch und kohärent, dass OpenAI aus Sorge vor potenziellem Missbrauch – etwa zur massenhaften Erstellung von Fake News – eine beispiellose Entscheidung traf: Sie veröffentlichten zunächst nur eine kleinere, weniger leistungsfähige Version des Modells.\n\n#### Die Rolle der KI im Durchbruch\n\nDie KI von GPT-2 demonstrierte eine beeindruckende Fähigkeit, lange und thematisch konsistente Textpassagen zu einem beliebigen Thema zu verfassen. Der Fortschritt lag in der reinen Skalierung des Modells und des Trainingsdatensatzes. GPT-2 zeigte, dass mit zunehmender Größe dieser Modelle neue, unerwartete Fähigkeiten entstehen, wie das Beantworten von Fragen oder das Zusammenfassen von Texten, ohne explizit darauf trainiert worden zu sein.\n\n#### Bedeutung und potenzieller Einfluss\n\nGPT-2 war ein Wendepunkt in der öffentlichen Debatte über KI-Sicherheit und -Ethik. Die Entscheidung, das Modell zurückzuhalten, entfachte eine globale Diskussion über die Verantwortung von KI-Forschungslaboren. Erst nach monatelanger Debatte und Forschung zu den potenziellen Risiken wurde das vollständige Modell im November 2019 veröffentlicht. GPT-2 machte der Welt die disruptiven Potenziale – im Guten wie im Schlechten – von fortschrittlicher KI bewusst."
}